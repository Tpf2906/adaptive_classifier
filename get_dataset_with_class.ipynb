{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36e16182",
   "metadata": {},
   "source": [
    "## Select sample from dataset with captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8dc93ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIG ===\n",
    "COCO_ROOT = './coco'\n",
    "OUTPUT_ROOT = './dataset_cap'\n",
    "NUM_TRAIN = 16000\n",
    "NUM_VAL = 4000\n",
    "random.seed(42)\n",
    "\n",
    "# === CREATE OUTPUT DIRECTORIES ===\n",
    "os.makedirs(OUTPUT_ROOT, exist_ok=True)\n",
    "\n",
    "ANNOTATIONS = {\n",
    "    \"train\": os.path.join(COCO_ROOT, \"annotations\", \"captions_train2017.json\"),\n",
    "    \"val\": os.path.join(COCO_ROOT, \"annotations\", \"captions_val2017.json\"),\n",
    "}\n",
    "INSTANCES = {\n",
    "    \"train\": os.path.join(COCO_ROOT, \"annotations\", \"instances_train2017.json\"),\n",
    "    \"val\": os.path.join(COCO_ROOT, \"annotations\", \"instances_val2017.json\"),\n",
    "}\n",
    "IMAGES = {\n",
    "    \"train\": os.path.join(COCO_ROOT, \"train2017\"),\n",
    "    \"val\": os.path.join(COCO_ROOT, \"val2017\"),\n",
    "}\n",
    "OUTPUT = {\n",
    "    \"train\": os.path.join(OUTPUT_ROOT, \"train\"),\n",
    "    \"val\": os.path.join(OUTPUT_ROOT, \"val\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "777e6891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LOAD CAPTIONS ===\n",
    "def load_coco_annotations(ann_path, min_captions=2):\n",
    "    with open(ann_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    id_to_filename = {img['id']: img['file_name'] for img in data['images']}\n",
    "    image_captions = {}\n",
    "\n",
    "    for ann in data['annotations']:\n",
    "        img_id = ann['image_id']\n",
    "        if img_id not in image_captions:\n",
    "            image_captions[img_id] = []\n",
    "        image_captions[img_id].append(ann['caption'])\n",
    "\n",
    "    entries = []\n",
    "    for img_id, captions in image_captions.items():\n",
    "        if len(captions) >= min_captions:\n",
    "            fname = id_to_filename[img_id]\n",
    "            entries.append((img_id, fname, captions))  # include image_id\n",
    "\n",
    "    return entries\n",
    "\n",
    "# === LOAD CATEGORIES FROM INSTANCES FILE ===\n",
    "def load_coco_categories(instances_path):\n",
    "    with open(instances_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    img_to_cats = {}\n",
    "    for ann in data['annotations']:\n",
    "        img_id = ann['image_id']\n",
    "        if img_id not in img_to_cats:\n",
    "            img_to_cats[img_id] = []\n",
    "        img_to_cats[img_id].append(ann['category_id'])\n",
    "\n",
    "    return img_to_cats\n",
    "\n",
    "# === MAIN EXTRACTION FUNCTION ===\n",
    "def process_split(split, num_samples):\n",
    "    print(f\"Processing {split} split...\")\n",
    "\n",
    "    os.makedirs(os.path.join(OUTPUT[split], \"images\"), exist_ok=True)\n",
    "\n",
    "    # Load captions and categories\n",
    "    entries = load_coco_annotations(ANNOTATIONS[split])\n",
    "    img_to_cats = load_coco_categories(INSTANCES[split])\n",
    "\n",
    "    print(f\"Total available {split} entries: {len(entries)}\")\n",
    "\n",
    "    random.shuffle(entries)\n",
    "    selected = []\n",
    "\n",
    "    for img_id, fname, captions in entries:\n",
    "        src_path = os.path.join(IMAGES[split], fname)\n",
    "        if os.path.exists(src_path):\n",
    "            selected.append((img_id, fname, captions))\n",
    "        if len(selected) == num_samples:\n",
    "            break\n",
    "\n",
    "    print(f\"Found {len(selected)} valid samples with existing images.\")\n",
    "\n",
    "    captions_dict = {}\n",
    "\n",
    "    for img_id, fname, captions in tqdm(selected):\n",
    "        src_path = os.path.join(IMAGES[split], fname)\n",
    "        dst_path = os.path.join(OUTPUT[split], \"images\", fname)\n",
    "        shutil.copy(src_path, dst_path)\n",
    "\n",
    "        categories = img_to_cats.get(img_id, [])\n",
    "        cat_id = max(set(categories), key=categories.count) if categories else -1\n",
    "        \n",
    "        if cat_id == -1:\n",
    "            continue\n",
    "\n",
    "        captions_dict[fname] = {\n",
    "            \"captions\": captions,\n",
    "            \"category_id\": cat_id\n",
    "        }\n",
    "\n",
    "    with open(os.path.join(OUTPUT[split], \"captions.json\"), \"w\") as f:\n",
    "        json.dump(captions_dict, f, indent=2)\n",
    "\n",
    "    print(f\"Saved {len(captions_dict)} {split} samples to {OUTPUT[split]}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40cbaae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train split...\n",
      "Total available train entries: 118287\n",
      "Found 8181 valid samples with existing images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8181/8181 [00:35<00:00, 228.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 8097 train samples to ./dataset_cap/train.\n",
      "Processing val split...\n",
      "Total available val entries: 5000\n",
      "Found 4000 valid samples with existing images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [00:10<00:00, 374.14it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 3967 val samples to ./dataset_cap/val.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === RUN ===\n",
    "process_split(\"train\", NUM_TRAIN)\n",
    "process_split(\"val\", NUM_VAL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
