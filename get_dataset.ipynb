{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36e16182",
   "metadata": {},
   "source": [
    "## Select sample from dataset with captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dc93ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIG ===\n",
    "COCO_ROOT = './coco'\n",
    "OUTPUT_ROOT = './dataset'\n",
    "NUM_TRAIN = 5000\n",
    "NUM_VAL = 1000\n",
    "random.seed(42)\n",
    "\n",
    "# === CREATE OUTPUT DIRECTORIES ===\n",
    "os.makedirs(OUTPUT_ROOT, exist_ok=True)\n",
    "\n",
    "ANNOTATIONS = {\n",
    "    \"train\": os.path.join(COCO_ROOT, \"annotations\", \"captions_train2017.json\"),\n",
    "    \"val\": os.path.join(COCO_ROOT, \"annotations\", \"captions_val2017.json\"),\n",
    "}\n",
    "IMAGES = {\n",
    "    \"train\": os.path.join(COCO_ROOT, \"train2017\"),\n",
    "    \"val\": os.path.join(COCO_ROOT, \"val2017\"),\n",
    "}\n",
    "OUTPUT = {\n",
    "    \"train\": os.path.join(OUTPUT_ROOT, \"train\"),\n",
    "    \"val\": os.path.join(OUTPUT_ROOT, \"val\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "777e6891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HELPER FUNCTION ===\n",
    "def load_coco_annotations(ann_path, min_captions=2):\n",
    "    with open(ann_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    id_to_filename = {img['id']: img['file_name'] for img in data['images']}\n",
    "    image_captions = {}\n",
    "\n",
    "    for ann in data['annotations']:\n",
    "        img_id = ann['image_id']\n",
    "        if img_id not in image_captions:\n",
    "            image_captions[img_id] = []\n",
    "        image_captions[img_id].append(ann['caption'])\n",
    "\n",
    "    entries = []\n",
    "    for img_id, captions in image_captions.items():\n",
    "        if len(captions) >= min_captions:\n",
    "            fname = id_to_filename[img_id]\n",
    "            entries.append((fname, captions))  # Keep all captions\n",
    "\n",
    "    return entries\n",
    "\n",
    "\n",
    "# === MAIN EXTRACTION FUNCTION ===\n",
    "def process_split(split, num_samples):\n",
    "    print(f\"Processing {split} split...\")\n",
    "\n",
    "    os.makedirs(os.path.join(OUTPUT[split], \"images\"), exist_ok=True)\n",
    "\n",
    "    entries = load_coco_annotations(ANNOTATIONS[split])\n",
    "    print(f\"Total available {split} entries: {len(entries)}\")\n",
    "\n",
    "    # Shuffle and select only those with existing images\n",
    "    random.shuffle(entries)\n",
    "    selected = []\n",
    "    for fname, caption in entries:\n",
    "        src_path = os.path.join(IMAGES[split], fname)\n",
    "        if os.path.exists(src_path):\n",
    "            selected.append((fname, caption))\n",
    "        if len(selected) == num_samples:\n",
    "            break\n",
    "\n",
    "    print(f\"Found {len(selected)} valid samples with existing images.\")\n",
    "\n",
    "    captions_dict = {}\n",
    "\n",
    "    for fname, caption in tqdm(selected):\n",
    "        src_path = os.path.join(IMAGES[split], fname)\n",
    "        dst_path = os.path.join(OUTPUT[split], \"images\", fname)\n",
    "        shutil.copy(src_path, dst_path)\n",
    "        captions_dict[fname] = caption\n",
    "\n",
    "    with open(os.path.join(OUTPUT[split], \"captions.json\"), \"w\") as f:\n",
    "        json.dump(captions_dict, f, indent=2)\n",
    "\n",
    "    print(f\"Saved {len(captions_dict)} {split} samples to {OUTPUT[split]}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40cbaae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train split...\n",
      "Total available train entries: 118287\n",
      "Found 5000 valid samples with existing images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:01<00:00, 4501.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 5000 train samples to ./dataset/train.\n",
      "Processing val split...\n",
      "Total available val entries: 5000\n",
      "Found 1000 valid samples with existing images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1701.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1000 val samples to ./dataset/val.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === RUN ===\n",
    "process_split(\"train\", NUM_TRAIN)\n",
    "process_split(\"val\", NUM_VAL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
