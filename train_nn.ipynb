{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c66605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import sys\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, recall_score, f1_score, precision_score, roc_auc_score,\n",
    "    top_k_accuracy_score\n",
    ")\n",
    "\n",
    "\n",
    "CLIP_FEATURES_DIR = \"clip_features\"\n",
    "VAL = CLIP_FEATURES_DIR + \"/val_features.pt\"\n",
    "SCALER = \"scaler_model.joblib\"\n",
    "PCA = \"pca_model.joblib\"\n",
    "LIME = \"top_k_lime_indices.joblib\"\n",
    "\n",
    "\n",
    "MAX_EPOCHS = 100\n",
    "EARLY_STOPPING = 10\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Set the random seed for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "016b96ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(file_path):\n",
    "    data = torch.load(file_path)\n",
    "    return data[\"image_features\"], data[\"text_features\"], data[\"filenames\"], data[\"labels\"]\n",
    "\n",
    "\n",
    "# Load train and validation features\n",
    "val_img_features, val_txt_features, _, val_labels = load_features(VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "982c3600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val shape: (1985, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Combine image and text features for training\n",
    "X_val = torch.cat((val_img_features, val_txt_features), dim=1)\n",
    "\n",
    "# Flatten features into a 2D matrix (samples x features)\n",
    "X_val = X_val.view(X_val.size(0), -1).numpy()\n",
    "\n",
    "# Print the shape of the features\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "\n",
    "# Convert labels to NumPy arrays\n",
    "y_val = val_labels.numpy()  \n",
    "\n",
    "# Load scaler and PCA models\n",
    "scaler = joblib.load(SCALER)\n",
    "pca = joblib.load(PCA)\n",
    "lime = joblib.load(LIME)\n",
    "\n",
    "# Scale and transform the features\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_val_pca = pca.transform(X_val_scaled)\n",
    "X_val_lime = X_val_scaled[:, lime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47cc8649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from: models_pca/SVM.joblib\n",
      "Loaded label encoder from: models_pca/label_encoder.joblib\n",
      "Loaded model from: models_pca/RBF.joblib\n",
      "Loaded label encoder from: models_pca/label_encoder.joblib\n",
      "Loaded model from: models_pca/RandomForest.joblib\n",
      "Loaded label encoder from: models_pca/label_encoder.joblib\n",
      "Loaded model from: models_pca/NaiveBayes.joblib\n",
      "Loaded label encoder from: models_pca/label_encoder.joblib\n",
      "Loaded model from: models_pca/LogisticRegression.joblib\n",
      "Loaded label encoder from: models_pca/label_encoder.joblib\n",
      "Loaded model from: models_pca/LDA.joblib\n",
      "Loaded label encoder from: models_pca/label_encoder.joblib\n",
      "Loaded model from: models_pca/KNN.joblib\n",
      "Loaded label encoder from: models_pca/label_encoder.joblib\n",
      "Loaded model from: models_pca/DecisionTree.joblib\n",
      "Loaded label encoder from: models_pca/label_encoder.joblib\n",
      "Loaded model from: models_pca/AdaBoost.joblib\n",
      "Loaded label encoder from: models_pca/label_encoder.joblib\n",
      "Loaded model from: models_pca/GBM.joblib\n",
      "Loaded label encoder from: models_pca/label_encoder.joblib\n",
      "Loaded model from: models_pca/XGBoost.joblib\n",
      "Loaded label encoder from: models_pca/label_encoder.joblib\n"
     ]
    }
   ],
   "source": [
    "from classifiers import (\n",
    "    SVMClassifier, RBFClassifier, RandomForestClassifier, NaiveBayesClassifier, \n",
    "    LogisticRegressionClassifier, LDAClassifier, KNNClassifier, DecisionTreeClassifier,\n",
    "    AdaBoostClassifier, GBMClassifier, XGBoostClassifier\n",
    ")\n",
    "\n",
    "from ensembler import EnsemblerClassifier\n",
    "\n",
    "# Instantiate classifiers\n",
    "classifiers = [\n",
    "    SVMClassifier(), RBFClassifier(), RandomForestClassifier(), NaiveBayesClassifier(),\n",
    "    LogisticRegressionClassifier(), LDAClassifier(), KNNClassifier(),\n",
    "    DecisionTreeClassifier(), AdaBoostClassifier(), GBMClassifier(),\n",
    "    XGBoostClassifier()\n",
    "]\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b981dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensembler import WeightGeneratorNN, train_step\n",
    "\n",
    "model = WeightGeneratorNN().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a6f3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiago/thesis/venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/tiago/thesis/venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/tiago/thesis/venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/tiago/thesis/venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/tiago/thesis/venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/tiago/thesis/venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/tiago/thesis/venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/tiago/thesis/venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/tiago/thesis/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/tiago/thesis/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Score=0.2667, Loss=-0.2667\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: Score=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# ✅ Check for convergence / early stopping\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m score > \u001b[43mbest_score\u001b[49m:\n\u001b[32m     14\u001b[39m     best_score = score\n\u001b[32m     15\u001b[39m     epochs_without_improvement = \u001b[32m0\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'best_score' is not defined"
     ]
    }
   ],
   "source": [
    "train_history = []\n",
    "best_score = -float(\"inf\")\n",
    "\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    # ✅ Generate new input_params each epoch\n",
    "    input_params = torch.rand(1, 7, device=DEVICE)  # Shape: (1, 7)\n",
    "\n",
    "    score, loss = train_step(model, optimizer, input_params, X_val_pca, y_val, classifiers, device=DEVICE)\n",
    "    train_history.append((score, loss))\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}: Score={score:.4f}, Loss={loss:.4f}\")\n",
    "\n",
    "    # ✅ Check for convergence / early stopping\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        epochs_without_improvement = 0\n",
    "        torch.save(model.state_dict(), \"best_weight_generator.pt\")  # Save best model\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    if epochs_without_improvement >= EARLY_STOPPING:\n",
    "        print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a75911",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, losses = zip(*train_history)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(scores, label=\"Validation Accuracy\")\n",
    "plt.plot(losses, label=\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.title(\"Weight Generator Training Progress\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
