{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17851834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import sys\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, recall_score, f1_score, precision_score, roc_auc_score,\n",
    "    top_k_accuracy_score\n",
    ")\n",
    "\n",
    "\n",
    "CLIP_FEATURES_DIR = \"clip_features\"\n",
    "VAL = CLIP_FEATURES_DIR + \"/val_features.pt\"\n",
    "SCALER = \"scaler_model.joblib\"\n",
    "PCA = \"pca_model.joblib\"\n",
    "LIME = \"top_k_lime_indices.joblib\"\n",
    "\n",
    "\n",
    "MAX_EPOCHS = 1000\n",
    "EARLY_STOPPING = 500\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Set the random seed for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1335a43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(file_path):\n",
    "    data = torch.load(file_path)\n",
    "    return data[\"image_features\"], data[\"text_features\"], data[\"filenames\"], data[\"labels\"]\n",
    "\n",
    "\n",
    "# Load train and validation features\n",
    "val_img_features, val_txt_features, _, val_labels = load_features(VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5de2b9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val shape: (1985, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Combine image and text features for training\n",
    "X_val = torch.cat((val_img_features, val_txt_features), dim=1)\n",
    "\n",
    "# Flatten features into a 2D matrix (samples x features)\n",
    "X_val = X_val.view(X_val.size(0), -1).numpy()\n",
    "\n",
    "# Print the shape of the features\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "\n",
    "# Convert labels to NumPy arrays\n",
    "y_val = val_labels.numpy()  \n",
    "\n",
    "# Load scaler and PCA models\n",
    "scaler = joblib.load(SCALER)\n",
    "pca = joblib.load(PCA)\n",
    "lime = joblib.load(LIME)\n",
    "\n",
    "# Scale and transform the features\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_val_pca = pca.transform(X_val_scaled)\n",
    "X_val_lime = X_val_scaled[:, lime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98807db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from: models_pca/SVM.joblib\n",
      "Loaded label encoder from: models_pca/label_encoder.joblib\n",
      "Loaded model from: models_pca/RBF.joblib\n",
      "Loaded label encoder from: models_pca/label_encoder.joblib\n",
      "Loaded model from: models_pca/RandomForest.joblib\n",
      "Loaded label encoder from: models_pca/label_encoder.joblib\n",
      "Loaded model from: models_pca/NaiveBayes.joblib\n",
      "Loaded label encoder from: models_pca/label_encoder.joblib\n",
      "Loaded model from: models_pca/LogisticRegression.joblib\n",
      "Loaded label encoder from: models_pca/label_encoder.joblib\n",
      "Loaded model from: models_pca/LDA.joblib\n",
      "Loaded label encoder from: models_pca/label_encoder.joblib\n",
      "Loaded model from: models_pca/KNN.joblib\n",
      "Loaded label encoder from: models_pca/label_encoder.joblib\n",
      "Loaded model from: models_pca/DecisionTree.joblib\n",
      "Loaded label encoder from: models_pca/label_encoder.joblib\n",
      "Loaded model from: models_pca/AdaBoost.joblib\n",
      "Loaded label encoder from: models_pca/label_encoder.joblib\n",
      "Loaded model from: models_pca/GBM.joblib\n",
      "Loaded label encoder from: models_pca/label_encoder.joblib\n",
      "Loaded model from: models_pca/XGBoost.joblib\n",
      "Loaded label encoder from: models_pca/label_encoder.joblib\n"
     ]
    }
   ],
   "source": [
    "from classifiers import (\n",
    "    SVMClassifier, RBFClassifier, RandomForestClassifier, NaiveBayesClassifier, \n",
    "    LogisticRegressionClassifier, LDAClassifier, KNNClassifier, DecisionTreeClassifier,\n",
    "    AdaBoostClassifier, GBMClassifier, XGBoostClassifier\n",
    ")\n",
    "\n",
    "from ensembler import EnsemblerClassifier\n",
    "\n",
    "# Instantiate classifiers\n",
    "classifiers = [\n",
    "    SVMClassifier(), RBFClassifier(), RandomForestClassifier(), NaiveBayesClassifier(),\n",
    "    LogisticRegressionClassifier(), LDAClassifier(), KNNClassifier(),\n",
    "    DecisionTreeClassifier(), AdaBoostClassifier(), GBMClassifier(),\n",
    "    XGBoostClassifier()\n",
    "]\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "862a7c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ACC ---\n",
      "Metrics:\n",
      "  accuracy: 0.6493702770780856\n",
      "  recall: 0.6493702770780856\n",
      "  f1_score: 0.6189334693848085\n",
      "  precision: 0.6173809469340443\n",
      "  roc_auc: 0.9416404505495262\n",
      "  top5_accuracy: 0.8997481108312343\n",
      "  inference_time: 9.356147527694702\n",
      "Updated Weights:\n",
      "[0.07719512283802032, 0.16135337948799133, 0.06362076848745346, 0.16351158916950226, 0.17402200400829315, 0.0, 0.0, 0.0, 0.08711770921945572, 0.13290242850780487, 0.14027704298496246]\n",
      "\n",
      "--- RECALL ---\n",
      "Metrics:\n",
      "  accuracy: 0.6337531486146095\n",
      "  recall: 0.6337531486146095\n",
      "  f1_score: 0.6142130942594919\n",
      "  precision: 0.6203917490051634\n",
      "  roc_auc: 0.9405445894466619\n",
      "  top5_accuracy: 0.9032745591939546\n",
      "  inference_time: 8.8707594871521\n",
      "Updated Weights:\n",
      "[0.303228497505188, 0.13721773028373718, 0.09513887763023376, 0.23675239086151123, 0.0, 0.08771230280399323, 0.0, 0.03424537926912308, 0.10570481419563293, 0.0, 0.0]\n",
      "\n",
      "--- F1 ---\n",
      "Metrics:\n",
      "  accuracy: 0.6463476070528967\n",
      "  recall: 0.6463476070528967\n",
      "  f1_score: 0.6223835033139069\n",
      "  precision: 0.616577005825025\n",
      "  roc_auc: 0.9401041911798013\n",
      "  top5_accuracy: 0.9007556675062972\n",
      "  inference_time: 3.3466830253601074\n",
      "Updated Weights:\n",
      "[0.3824222981929779, 0.0, 0.0, 0.1668625921010971, 0.2866675555706024, 0.0, 0.0, 0.0, 0.0, 0.1640474945306778, 0.0]\n",
      "\n",
      "--- PRECISION ---\n",
      "Metrics:\n",
      "  accuracy: 0.6418136020151134\n",
      "  recall: 0.6418136020151134\n",
      "  f1_score: 0.6168829099108196\n",
      "  precision: 0.6205134816104734\n",
      "  roc_auc: 0.9378252997330851\n",
      "  top5_accuracy: 0.9042821158690176\n",
      "  inference_time: 8.779212713241577\n",
      "Updated Weights:\n",
      "[0.2946789264678955, 0.25208231806755066, 0.0, 0.2509060502052307, 0.0, 0.0, 0.0, 0.20233266055583954, 0.0, 0.0, 0.0]\n",
      "\n",
      "--- TOP5 ---\n",
      "Metrics:\n",
      "  accuracy: 0.5622166246851386\n",
      "  recall: 0.5622166246851386\n",
      "  f1_score: 0.5641753237466651\n",
      "  precision: 0.5998869952655739\n",
      "  roc_auc: 0.93533977324051\n",
      "  top5_accuracy: 0.9133501259445844\n",
      "  inference_time: 3.2631583213806152\n",
      "Updated Weights:\n",
      "[0.2622438371181488, 0.0, 0.0, 0.3989412188529968, 0.0, 0.0, 0.0, 0.0, 0.3388148844242096, 0.0, 0.0]\n",
      "\n",
      "--- AUC ---\n",
      "Metrics:\n",
      "  accuracy: 0.5118387909319899\n",
      "  recall: 0.5118387909319899\n",
      "  f1_score: 0.4773661410895331\n",
      "  precision: 0.47109952159362783\n",
      "  roc_auc: 0.9290893661009583\n",
      "  top5_accuracy: 0.890176322418136\n",
      "  inference_time: 5.258897304534912\n",
      "Updated Weights:\n",
      "[0.0, 0.33038970828056335, 0.37122973799705505, 0.0, 0.0, 0.0, 0.0, 0.298380583524704, 0.0, 0.0, 0.0]\n",
      "\n",
      "--- TIME ---\n",
      "Metrics:\n",
      "  accuracy: 0.46700251889168765\n",
      "  recall: 0.46700251889168765\n",
      "  f1_score: 0.4384078701932947\n",
      "  precision: 0.43136658709544345\n",
      "  roc_auc: 0.7925719522263934\n",
      "  top5_accuracy: 0.745088161209068\n",
      "  inference_time: 0.049428701400756836\n",
      "Updated Weights:\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Load JSON file\n",
    "with open('ensemble_results.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Function to process each entry\n",
    "def process_entry(entry):\n",
    "    metrics = {\n",
    "        \"accuracy\": entry[\"accuracy\"],\n",
    "        \"recall\": entry[\"recall\"],\n",
    "        \"f1_score\": entry[\"f1_score\"],\n",
    "        \"precision\": entry[\"precision\"],\n",
    "        \"roc_auc\": entry[\"roc_auc\"],\n",
    "        \"top5_accuracy\": entry[\"top5_accuracy\"],\n",
    "        \"inference_time\": entry[\"inference_time\"]\n",
    "    }\n",
    "\n",
    "    weights = entry[\"selected_weights\"]\n",
    "    activations = entry[\"activation_bits\"]\n",
    "\n",
    "    weight_index = 0\n",
    "    updated_weights = []\n",
    "\n",
    "    for bit in activations:\n",
    "        if bit > 0.5 and weight_index < len(weights):\n",
    "            updated_weights.append(weights[weight_index])\n",
    "            weight_index += 1\n",
    "        else:\n",
    "            updated_weights.append(0.0)\n",
    "\n",
    "    return {\n",
    "        \"metrics\": metrics,\n",
    "        \"updated_weights\": updated_weights\n",
    "    }\n",
    "\n",
    "# Dictionary to hold results for each key\n",
    "results = {}\n",
    "\n",
    "# Loop through all keys in the file\n",
    "for key, entry in data.items():\n",
    "    results[key] = process_entry(entry)\n",
    "\n",
    "# Example: print everything nicely\n",
    "for key, info in results.items():\n",
    "    print(f\"\\n--- {key.upper()} ---\")\n",
    "    print(\"Metrics:\")\n",
    "    for m_key, m_val in info[\"metrics\"].items():\n",
    "        print(f\"  {m_key}: {m_val}\")\n",
    "    print(\"Updated Weights:\")\n",
    "    print(info[\"updated_weights\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f2e962a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6493702770780856, 0.6493702770780856, 0.6189334693848085, 0.6173809469340443, 0.9416404505495262, 0.8997481108312343, 9.356147527694702, 0.6337531486146095, 0.6337531486146095, 0.6142130942594919, 0.6203917490051634, 0.9405445894466619, 0.9032745591939546, 8.8707594871521, 0.6463476070528967, 0.6463476070528967, 0.6223835033139069, 0.616577005825025, 0.9401041911798013, 0.9007556675062972, 3.3466830253601074, 0.6418136020151134, 0.6418136020151134, 0.6168829099108196, 0.6205134816104734, 0.9378252997330851, 0.9042821158690176, 8.779212713241577, 0.5622166246851386, 0.5622166246851386, 0.5641753237466651, 0.5998869952655739, 0.93533977324051, 0.9133501259445844, 3.2631583213806152, 0.5118387909319899, 0.5118387909319899, 0.4773661410895331, 0.47109952159362783, 0.9290893661009583, 0.890176322418136, 5.258897304534912, 0.46700251889168765, 0.46700251889168765, 0.4384078701932947, 0.43136658709544345, 0.7925719522263934, 0.745088161209068, 0.049428701400756836]\n"
     ]
    }
   ],
   "source": [
    "metrics = []\n",
    "\n",
    "metric_keys = [\n",
    "    \"accuracy\", \"recall\", \"f1_score\",\n",
    "    \"precision\", \"roc_auc\", \"top5_accuracy\",\n",
    "    \"inference_time\"\n",
    "]\n",
    "\n",
    "# Go through each key and extract just the metric values\n",
    "for entry in data.values():\n",
    "    for key in metric_keys:\n",
    "        metrics.append(entry[key])\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9899fd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from ensembler import FinalWeightGeneratorNN\n",
    "\n",
    "#load model\n",
    "model_path = \"final_weight_generator.pth\"\n",
    "if os.path.exists(model_path):\n",
    "    model = FinalWeightGeneratorNN()\n",
    "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "    model.to(DEVICE)\n",
    "    print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d8029b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input parameters: tensor([[0.3264, 0.9967, 0.0706, 0.2893, 0.5037, 0.1414, 0.5756]],\n",
      "       device='cuda:0')\n",
      "Input tensor shape: torch.Size([1, 56])\n"
     ]
    }
   ],
   "source": [
    "input_params = torch.rand(1, 7, device=DEVICE)\n",
    "print(\"Input parameters:\", input_params)\n",
    "# Create input_parsms 1 0 0 0 0 0 0\n",
    "#input_params = torch.tensor([[1, 0, 0, 0, 0, 0, 0]], dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "\n",
    "metrics_tensor = torch.tensor(metrics, dtype=torch.float32, device=DEVICE).unsqueeze(0)\n",
    "\n",
    "input_tensor = torch.cat((input_params, metrics_tensor), dim=1)  # Concatenate along the feature dimension\n",
    "print(\"Input tensor shape:\", input_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b043d472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input parameters: tensor([[0.3264, 0.9967, 0.0706, 0.2893, 0.5037, 0.1414, 0.5756]],\n",
      "       device='cuda:0')\n",
      "Activation bits: [ 1.5121626e+00  1.4294205e+00  7.5284433e-01  1.6619697e+00\n",
      " -9.1480551e+00  1.0439637e-01 -9.8547602e+00  3.7888288e-03\n",
      "  8.4746683e-01 -8.9760895e+00 -8.0085325e+00]\n",
      "Selected classifiers: ['SVMClassifier', 'RBFClassifier', 'RandomForestClassifierWrapper', 'NaiveBayesClassifier', 'AdaBoostClassifierWrapper']\n",
      "Selected weights: [0.32425222 0.16633856 0.11918914 0.2666491  0.12357098]\n"
     ]
    }
   ],
   "source": [
    "activation, weights = model(input_tensor)\n",
    "\n",
    "activation_bits = activation.detach().cpu().numpy().flatten()\n",
    "weight_values = weights.detach().cpu().numpy().flatten()\n",
    "    \n",
    "\n",
    "# Select classifiers with activation > 0.5\n",
    "activated_indices = np.where(activation_bits > 0.5)[0]\n",
    "if len(activated_indices) == 0:\n",
    "    activated_indices = [np.argmax(activation_bits)]\n",
    "    \n",
    "\n",
    "selected_classifiers = [\n",
    "    classifiers[i] for i in activated_indices]\n",
    "selected_weights = [weight_values[i] for i in activated_indices]\n",
    "\n",
    "# Normalize weights\n",
    "selected_weights = np.array(selected_weights)\n",
    "selected_weights /= selected_weights.sum()\n",
    "\n",
    "print(\"Input parameters:\", input_params)\n",
    "print(f\"Activation bits: {activation_bits}\")\n",
    "print(f\"Selected classifiers: {[type(clf).__name__ for clf in selected_classifiers]}\")\n",
    "print(f\"Selected weights: {selected_weights}\")\n",
    "\n",
    "# Create ensemble\n",
    "ensemble = EnsemblerClassifier(zip(selected_classifiers, selected_weights))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
