{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f9d3211",
   "metadata": {},
   "source": [
    "## Train Base Classifiers and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ed2fbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "CLIP_FEATURES_DIR = \"clip_features\"\n",
    "TRAIN = CLIP_FEATURES_DIR + \"/train_features.pt\"\n",
    "VAL = CLIP_FEATURES_DIR + \"/val_features.pt\"\n",
    "SCALER = \"scaler_model.joblib\"\n",
    "PCA = \"pca_model.joblib\"\n",
    "LIME = \"top_k_lime_indices.joblib\"\n",
    "\n",
    "MIN_SAMPLES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d711d31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(file_path):\n",
    "    data = torch.load(file_path)\n",
    "    return data[\"image_features\"], data[\"text_features\"], data[\"filenames\"], data[\"labels\"]\n",
    "\n",
    "\n",
    "# Load train and validation features\n",
    "train_img_features, train_txt_features, _, train_labels = load_features(TRAIN)\n",
    "val_img_features, val_txt_features, _, val_labels = load_features(VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "347194a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (7919, 1024)\n",
      "X_val shape: (1985, 1024)\n",
      "X_train_pca shape: (7919, 563)\n",
      "X_val_pca shape: (1985, 563)\n",
      "X_train_lime shape: (7919, 250)\n",
      "X_val_lime shape: (1985, 250)\n"
     ]
    }
   ],
   "source": [
    "# Combine image and text features for training\n",
    "X_train = torch.cat((train_img_features, train_txt_features), dim=1)\n",
    "X_val = torch.cat((val_img_features, val_txt_features), dim=1)\n",
    "\n",
    "# Flatten features into a 2D matrix (samples x features)\n",
    "X_train = X_train.view(X_train.size(0), -1).numpy()\n",
    "X_val = X_val.view(X_val.size(0), -1).numpy()\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "\n",
    "# Convert labels to NumPy arrays\n",
    "y_train = train_labels.numpy()\n",
    "y_val = val_labels.numpy()  \n",
    "\n",
    "# Load scaler and PCA models\n",
    "scaler = joblib.load(SCALER)\n",
    "pca = joblib.load(PCA)\n",
    "lime = joblib.load(LIME)\n",
    "\n",
    "# Scale and transform the features\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "X_train_pca = pca.transform(X_train_scaled)\n",
    "X_val_pca = pca.transform(X_val_scaled)\n",
    "\n",
    "X_train_lime = X_train_scaled[:, lime]\n",
    "X_val_lime = X_val_scaled[:, lime]\n",
    "\n",
    "print(f\"X_train_pca shape: {X_train_pca.shape}\")\n",
    "print(f\"X_val_pca shape: {X_val_pca.shape}\")\n",
    "print(f\"X_train_lime shape: {X_train_lime.shape}\")\n",
    "print(f\"X_val_lime shape: {X_val_lime.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e110693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "class_counts = dict(zip(unique, counts))\n",
    "\n",
    "# Filter mask for valid classes\n",
    "valid_classes = [cls for cls, count in class_counts.items() if count >= MIN_SAMPLES]\n",
    "\n",
    "# Create mask for training examples with valid classes\n",
    "mask = np.isin(y_train, valid_classes)\n",
    "\n",
    "# Filter data\n",
    "X_train_pca = X_train_pca[mask]\n",
    "X_train_lime = X_train_lime[mask]\n",
    "\n",
    "y_train = y_train[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea83c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    }
   ],
   "source": [
    "print(len(valid_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03534db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM...\n",
      "Evaluating SVM...\n",
      "SVM Accuracy: 0.6398\n",
      "Model saved to: models_lime_cal/SVM.joblib\n",
      "Label encoder saved to: models_lime_cal/label_encoder.joblib\n",
      "Training RBF...\n",
      "Evaluating RBF...\n",
      "RBF Accuracy: 0.6398\n",
      "Model saved to: models_lime_cal/RBF.joblib\n",
      "Label encoder saved to: models_lime_cal/label_encoder.joblib\n",
      "Training Random Forest...\n",
      "Evaluating Random Forest...\n",
      "Random Forest Accuracy: 0.6045\n",
      "Model saved to: models_lime_cal/RandomForest.joblib\n",
      "Label encoder saved to: models_lime_cal/label_encoder.joblib\n",
      "Training Naive Bayes...\n",
      "Evaluating Naive Bayes...\n",
      "Naive Bayes Accuracy: 0.4448\n",
      "Model saved to: models_lime_cal/NaiveBayes.joblib\n",
      "Label encoder saved to: models_lime_cal/label_encoder.joblib\n",
      "Training Logistic Regression...\n",
      "Evaluating Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.5783\n",
      "Model saved to: models_lime_cal/LogisticRegression.joblib\n",
      "Label encoder saved to: models_lime_cal/label_encoder.joblib\n",
      "Training LDA...\n",
      "Evaluating LDA...\n",
      "LDA Accuracy: 0.5390\n",
      "Model saved to: models_lime_cal/LDA.joblib\n",
      "Label encoder saved to: models_lime_cal/label_encoder.joblib\n",
      "Training KNN...\n",
      "Evaluating KNN...\n",
      "KNN Accuracy: 0.6181\n",
      "Model saved to: models_lime_cal/KNN.joblib\n",
      "Label encoder saved to: models_lime_cal/label_encoder.joblib\n",
      "Training Decision Tree...\n",
      "Evaluating Decision Tree...\n",
      "Decision Tree Accuracy: 0.3909\n",
      "Model saved to: models_lime_cal/DecisionTree.joblib\n",
      "Label encoder saved to: models_lime_cal/label_encoder.joblib\n",
      "Training AdaBoost...\n",
      "Evaluating AdaBoost...\n",
      "AdaBoost Accuracy: 0.3783\n",
      "Model saved to: models_lime_cal/AdaBoost.joblib\n",
      "Label encoder saved to: models_lime_cal/label_encoder.joblib\n",
      "Training Gradient Boosting...\n",
      "Evaluating Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.5139\n",
      "Model saved to: models_lime_cal/GBM.joblib\n",
      "Label encoder saved to: models_lime_cal/label_encoder.joblib\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiago/thesis/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [04:24:21] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/tiago/thesis/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [04:24:41] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/tiago/thesis/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [04:25:01] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating XGBoost...\n",
      "XGBoost Accuracy: 0.6146\n",
      "Model saved to: models_lime_cal/XGBoost.joblib\n",
      "Label encoder saved to: models_lime_cal/label_encoder.joblib\n"
     ]
    }
   ],
   "source": [
    "from classifiers import (\n",
    "    SVMClassifier, RBFClassifier, RandomForestClassifier, NaiveBayesClassifier, \n",
    "    LogisticRegressionClassifier, LDAClassifier, KNNClassifier, DecisionTreeClassifier,\n",
    "    AdaBoostClassifier, GBMClassifier, XGBoostClassifier\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    \"SVM\": SVMClassifier(),\n",
    "    \"RBF\": RBFClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Naive Bayes\": NaiveBayesClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegressionClassifier(),\n",
    "    \"LDA\": LDAClassifier(),\n",
    "    \"KNN\": KNNClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Gradient Boosting\": GBMClassifier(),\n",
    "    \"XGBoost\": XGBoostClassifier()\n",
    "}\n",
    "\n",
    "\n",
    "# Train and evaluate classifiers\n",
    "results = {}\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    clf.train(X_train_lime, y_train)\n",
    "        \n",
    "    y_pred = clf.classify(X_val_lime)\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    results[name] = accuracy\n",
    "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
    "    clf.save(model_dir=\"models_lime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec6d27fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SVM': 0.6397984886649875, 'RBF': 0.6397984886649875, 'Random Forest': 0.6045340050377834, 'Naive Bayes': 0.4448362720403023, 'Logistic Regression': 0.5783375314861461, 'LDA': 0.5390428211586902, 'KNN': 0.6181360201511334, 'Decision Tree': 0.39093198992443323, 'AdaBoost': 0.3783375314861461, 'Gradient Boosting': 0.5138539042821159, 'XGBoost': 0.6146095717884131}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d52e649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from: models_lime_cal/SVM.joblib\n",
      "Loaded label encoder from: models_lime_cal/label_encoder.joblib\n"
     ]
    }
   ],
   "source": [
    "svm = SVMClassifier()\n",
    "svm.load(model_dir=\"models_lime_cal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a4685c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 563 features, but SVC is expecting 250 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Test the classify method on the first sample of X_val_pca\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43msvm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclassify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val_pca\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m      6\u001b[39m res = svm.classify_proba(X_val_pca[\u001b[32m1\u001b[39m].reshape(\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m))\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thesis/adaptive_classifier/classifiers/base_classifier.py:48\u001b[39m, in \u001b[36mBaseClassifier.classify\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mSubclasses must define self.model.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m y_pred_encoded = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.label_encoder.inverse_transform(y_pred_encoded)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thesis/venv/lib/python3.12/site-packages/sklearn/calibration.py:525\u001b[39m, in \u001b[36mCalibratedClassifierCV.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    509\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Predict the target of new samples.\u001b[39;00m\n\u001b[32m    510\u001b[39m \n\u001b[32m    511\u001b[39m \u001b[33;03mThe predicted class is the class that has the highest probability,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    522\u001b[39m \u001b[33;03m    The predicted class.\u001b[39;00m\n\u001b[32m    523\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    524\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.classes_[np.argmax(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, axis=\u001b[32m1\u001b[39m)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thesis/venv/lib/python3.12/site-packages/sklearn/calibration.py:501\u001b[39m, in \u001b[36mCalibratedClassifierCV.predict_proba\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    499\u001b[39m mean_proba = np.zeros((_num_samples(X), \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.classes_)))\n\u001b[32m    500\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m calibrated_classifier \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.calibrated_classifiers_:\n\u001b[32m--> \u001b[39m\u001b[32m501\u001b[39m     proba = \u001b[43mcalibrated_classifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    502\u001b[39m     mean_proba += proba\n\u001b[32m    504\u001b[39m mean_proba /= \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.calibrated_classifiers_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thesis/venv/lib/python3.12/site-packages/sklearn/calibration.py:725\u001b[39m, in \u001b[36m_CalibratedClassifier.predict_proba\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    709\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    710\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Calculate calibrated probabilities.\u001b[39;00m\n\u001b[32m    711\u001b[39m \n\u001b[32m    712\u001b[39m \u001b[33;03m    Calculates classification calibrated probabilities\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    723\u001b[39m \u001b[33;03m        The predicted probabilities. Can be exact zeros.\u001b[39;00m\n\u001b[32m    724\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m725\u001b[39m     predictions, _ = \u001b[43m_get_response_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    727\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecision_function\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpredict_proba\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    730\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m predictions.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m    731\u001b[39m         \u001b[38;5;66;03m# Reshape binary output from `(n_samples,)` to `(n_samples, 1)`\u001b[39;00m\n\u001b[32m    732\u001b[39m         predictions = predictions.reshape(-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thesis/venv/lib/python3.12/site-packages/sklearn/utils/_response.py:214\u001b[39m, in \u001b[36m_get_response_values\u001b[39m\u001b[34m(estimator, X, response_method, pos_label, return_response_method_used)\u001b[39m\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m target_type == \u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    212\u001b[39m         pos_label = classes[-\u001b[32m1\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m y_pred = \u001b[43mprediction_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prediction_method.\u001b[34m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mpredict_proba\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpredict_log_proba\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    217\u001b[39m     y_pred = _process_predict_proba(\n\u001b[32m    218\u001b[39m         y_pred=y_pred,\n\u001b[32m    219\u001b[39m         target_type=target_type,\n\u001b[32m    220\u001b[39m         classes=classes,\n\u001b[32m    221\u001b[39m         pos_label=pos_label,\n\u001b[32m    222\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thesis/venv/lib/python3.12/site-packages/sklearn/svm/_base.py:787\u001b[39m, in \u001b[36mBaseSVC.decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    760\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    761\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Evaluate the decision function for the samples in X.\u001b[39;00m\n\u001b[32m    762\u001b[39m \n\u001b[32m    763\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    785\u001b[39m \u001b[33;03m    transformation of ovo decision function.\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m     dec = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    788\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.decision_function_shape == \u001b[33m\"\u001b[39m\u001b[33movr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.classes_) > \u001b[32m2\u001b[39m:\n\u001b[32m    789\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _ovr_decision_function(dec < \u001b[32m0\u001b[39m, -dec, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.classes_))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thesis/venv/lib/python3.12/site-packages/sklearn/svm/_base.py:536\u001b[39m, in \u001b[36mBaseLibSVM._decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    522\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Evaluates the decision function for the samples in X.\u001b[39;00m\n\u001b[32m    523\u001b[39m \n\u001b[32m    524\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    532\u001b[39m \u001b[33;03m    in the model.\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    534\u001b[39m \u001b[38;5;66;03m# NOTE: _validate_for_predict contains check for is_fitted\u001b[39;00m\n\u001b[32m    535\u001b[39m \u001b[38;5;66;03m# hence must be placed before any other attributes are used.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m X = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_for_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    537\u001b[39m X = \u001b[38;5;28mself\u001b[39m._compute_kernel(X)\n\u001b[32m    539\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sparse:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thesis/venv/lib/python3.12/site-packages/sklearn/svm/_base.py:614\u001b[39m, in \u001b[36mBaseLibSVM._validate_for_predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    611\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    613\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.kernel):\n\u001b[32m--> \u001b[39m\u001b[32m614\u001b[39m     X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    615\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    617\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    618\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sparse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp.issparse(X):\n\u001b[32m    625\u001b[39m     X = sp.csr_matrix(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thesis/venv/lib/python3.12/site-packages/sklearn/utils/validation.py:2965\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2962\u001b[39m     out = X, y\n\u001b[32m   2964\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m2965\u001b[39m     \u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2967\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thesis/venv/lib/python3.12/site-packages/sklearn/utils/validation.py:2829\u001b[39m, in \u001b[36m_check_n_features\u001b[39m\u001b[34m(estimator, X, reset)\u001b[39m\n\u001b[32m   2826\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   2828\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_features != estimator.n_features_in_:\n\u001b[32m-> \u001b[39m\u001b[32m2829\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2830\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2831\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator.n_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m features as input.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2832\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: X has 563 features, but SVC is expecting 250 features as input."
     ]
    }
   ],
   "source": [
    "# Test the classify method on the first sample of X_val_pca\n",
    "\n",
    "\n",
    "print(svm.classify(X_val_pca[1].reshape(1, -1)))\n",
    "\n",
    "res = svm.classify_proba(X_val_pca[1].reshape(1, -1))\n",
    "\n",
    "print(res)\n",
    "print(len(res[0]))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
